


#we start by importing important libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor


#load the data
data = pd.read_csv("housing.csv")
data


# checking for missing values
data.info()


# we observe that we have in fact some missing data in column 'total_bedrooms' and we need to fill or delete the lines with missing data in order
# to correctly train the models, for now, we are gonna choose to delete the lines

data.dropna(inplace = True)
data





#we can make a histogram of every column in the train_data

data.hist(figsize=(15, 7))


# we are also going to analyze correlations between the data.

data.drop(['ocean_proximity'], axis=1).corr() # since 'ocean_proximity' is not a numerical column, we need to drop it.


# if you're struggling to understand the correlation clearly, we can use a heatmap.  

plt.figure(figsize=(15,7))
sns.heatmap(data.drop(['ocean_proximity'], axis=1).corr(), annot = True, cmap="YlGnBu")





# checking the distribution of categories in the 'ocean_proximity' column  
data['ocean_proximity'].value_counts()


# transforming the string labeling in multi-class classification
data = data.join(pd.get_dummies(data['ocean_proximity']))
data = data.drop(['ocean_proximity'], axis=1)

data


plt.figure(figsize=(15,7))
sns.heatmap(data.corr(), annot = True, cmap="YlGnBu")


#we save a copy for another test with 'total_bedrooms' and 'total_rooms' and not 'bedrooms_per_room'
data_copy = data.copy()

# since total rooms and total bedrooms represent absolute counts, we will convert them into a ratio  
data['bedrooms_per_room'] = data['total_bedrooms'] / data['total_rooms']

# dropping total_rooms and total_bedrooms since their information is captured in the ratio
data = data.drop(columns=['total_rooms', 'total_bedrooms'])

#droping longitude and latitude because it can affect the model performance
data = data.drop(columns=['longitude', 'latitude'])
data_copy = data_copy.drop(columns=['longitude', 'latitude'])

data


# we need to split the data into features (X) and target variable (Y)  
# this step is essential for training our models correctly.  

x = data.drop(['median_house_value'], axis=1)
y = data['median_house_value']

x


# split the data into train and test
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)






regresion = LinearRegression()


regresion.fit(x_train, y_train)





rd_forest = RandomForestRegressor()


rd_forest.fit(x_train, y_train)







# model Scores (R² Score)
regresion_score = regresion.score(x_test, y_test)
rd_forest_score = rd_forest.score(x_test, y_test)

# making predictions
regresion_pred = regresion.predict(x_test)
rd_forest_pred = rd_forest.predict(x_test)

# mean Absolute Error (MAE)
regresion_mae = mean_absolute_error(y_test, regresion_pred)
rd_forest_mae = mean_absolute_error(y_test, rd_forest_pred)

print(f"Linear Regression:")
print(f"   - R² Score: {regresion_score:.4f}")
print(f"   - Mean Absolute Error (MAE): {regresion_mae:.4f}")

print("\nRandom Forest:")
print(f"   - R² Score: {rd_forest_score:.4f}")
print(f"   - Mean Absolute Error (MAE): {rd_forest_mae:.4f}")






x = data_copy.drop(['median_house_value'], axis=1)
y = data_copy['median_house_value']

x


x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)


regresion2 = LinearRegression()
regresion2.fit(x_train, y_train)


rd_forest2 = RandomForestRegressor()
rd_forest2.fit(x_train, y_train)


# model Scores (R² Score)
regresion_score = regresion2.score(x_test, y_test)
rd_forest_score = rd_forest2.score(x_test, y_test)

# making predictions
regresion_pred = regresion2.predict(x_test)
rd_forest_pred = rd_forest2.predict(x_test)

# mean Absolute Error (MAE)
regresion_mae = mean_absolute_error(y_test, regresion_pred)
rd_forest_mae = mean_absolute_error(y_test, rd_forest_pred)

print(f"Linear Regression:")
print(f"   - R² Score: {regresion_score:.4f}")
print(f"   - Mean Absolute Error (MAE): {regresion_mae:.4f}")

print("\nRandom Forest:")
print(f"   - R² Score: {rd_forest_score:.4f}")
print(f"   - Mean Absolute Error (MAE): {rd_forest_mae:.4f}")



import warnings
warnings.filterwarnings("ignore", category=UserWarning)

def predict_house_price(features, model):
    features_array = np.array(features).reshape(1, -1)
    predicted_price = model.predict(features_array)[0]
    print(f"Predicted House Price: ${predicted_price:,.2f}")


# Features: [housing_median_age, population, households, median_income, <1H OCEAN, INLAND, ISLAND, NEAR BAY, NEAR OCEAN, ratio]
example_features = [30.0, 5000, 1000, 8.3252, 0, 1, 0, 0, 0, 0.5]  # Example with population and ratio  
# Features: [housing_median_age, total_rooms, total_bedrooms, population, households, median_income, <1H OCEAN, INLAND, ISLAND, NEAR BAY, NEAR OCEAN]
example_features2 = [30.0, 3500, 1000, 10000, 5, 8.3252, 0, 1, 0, 0, 0]  # Corrected total_bedrooms value  


predict_house_price(example_features, regresion)
predict_house_price(example_features, rd_forest)

predict_house_price(example_features2, regresion2)
predict_house_price(example_features2, rd_forest2)
